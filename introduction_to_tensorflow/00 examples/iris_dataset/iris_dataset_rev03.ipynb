{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: C:\\Users\\LONAA32\\.keras\\datasets\\iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "test_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "test_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(test_dataset_url),\n",
    "                                          origin=test_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(file_path, batch_size=1):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(file_path,\n",
    "                                                    batch_size,\n",
    "                                                    column_names=COLUMN_NAMES,\n",
    "                                                    label_name=LABEL_NAME)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "# column order in CSV file\n",
    "COLUMN_NAMES = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "FEATURE_NAMES = COLUMN_NAMES[:-1]\n",
    "LABEL_NAME = COLUMN_NAMES[-1]\n",
    "\n",
    "print(\"Features: {}\".format(FEATURE_NAMES))\n",
    "print(\"Label: {}\".format(LABEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = create_dataset(train_dataset_fp, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_dataset(test_dataset_fp, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sepal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([6.6, 4.9, 6.4, 7.2, 5.6, 5.4, 4.9, 6.8, 5.3, 6.9, 6.7, 4.9, 4.6,\n",
      "       7.3, 6.5, 4.9, 7.7, 5.8, 6.5, 7.2, 6.7, 6.1, 5.7, 4.4, 5.4, 4.8,\n",
      "       7.7, 7.6, 5. , 5.7, 6.1, 6.6], dtype=float32)>), ('sepal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([3. , 3. , 3.1, 3. , 2.7, 3.4, 3.1, 3.2, 3.7, 3.2, 3.1, 2.5, 3.4,\n",
      "       2.9, 3.2, 3.1, 3.8, 4. , 3. , 3.6, 3.3, 2.8, 2.8, 2.9, 3.9, 3.1,\n",
      "       2.8, 3. , 3.5, 3. , 2.9, 2.9], dtype=float32)>), ('petal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([4.4, 1.4, 5.5, 5.8, 4.2, 1.5, 1.5, 5.9, 1.5, 5.7, 5.6, 4.5, 1.4,\n",
      "       6.3, 5.1, 1.5, 6.7, 1.2, 5.5, 6.1, 5.7, 4. , 4.1, 1.4, 1.7, 1.6,\n",
      "       6.7, 6.6, 1.6, 4.2, 4.7, 4.6], dtype=float32)>), ('petal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([1.4, 0.2, 1.8, 1.6, 1.3, 0.4, 0.1, 2.3, 0.2, 2.3, 2.4, 1.7, 0.3,\n",
      "       1.8, 2. , 0.1, 2.2, 0.2, 1.8, 2.5, 2.1, 1.3, 1.3, 0.2, 0.4, 0.2,\n",
      "       2. , 2.1, 0.6, 1.2, 1.4, 1.3], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('sepal_length', array([5.7, 6.1, 6.8, 5.8, 6. , 6. , 5. , 6.4, 6.9, 6.3, 6.5, 4.6, 5.6,\n",
      "       5.7, 6.5, 6.4, 4.9, 6.6, 6.1, 5.8, 6.9, 4.4, 6.5, 6.7, 6.7, 4.9,\n",
      "       7.2, 6.2, 6.5, 4.9, 5.7, 7.2], dtype=float32)), ('sepal_width', array([3. , 2.9, 2.8, 2.6, 2.7, 2.9, 3.5, 2.8, 3.1, 3.3, 3. , 3.1, 2.5,\n",
      "       2.8, 3. , 3.1, 3.1, 3. , 2.8, 2.7, 3.2, 3. , 3.2, 3.3, 3.1, 3.1,\n",
      "       3.2, 2.2, 2.8, 3.1, 2.9, 3. ], dtype=float32)), ('petal_length', array([4.2, 4.7, 4.8, 4. , 5.1, 4.5, 1.3, 5.6, 4.9, 6. , 5.2, 1.5, 3.9,\n",
      "       4.5, 5.5, 5.5, 1.5, 4.4, 4. , 5.1, 5.7, 1.3, 5.1, 5.7, 4.4, 1.5,\n",
      "       6. , 4.5, 4.6, 1.5, 4.2, 5.8], dtype=float32)), ('petal_width', array([1.2, 1.4, 1.4, 1.2, 1.6, 1.5, 0.3, 2.2, 1.5, 2.5, 2. , 0.2, 1.1,\n",
      "       1.3, 1.8, 1.8, 0.1, 1.4, 1.3, 1.9, 2.3, 0.2, 2. , 2.1, 1.4, 0.1,\n",
      "       1.8, 1.5, 1.5, 0.1, 1.3, 1.6], dtype=float32))]), array([1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 2, 0, 1, 1, 2, 2, 0, 1, 1, 2, 2, 0,\n",
      "       2, 2, 1, 0, 2, 1, 1, 0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "for element in train_dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "    \"\"\"Pack the features into a single array.\"\"\"\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.7 3.2 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.7 3.  4.2 1.2]], shape=(5, 4), dtype=float32)\n",
      "tf.Tensor([0 0 1 1 1 0 2 1 2 2 2 2 2 1 2 0 2 2 2 2 0 1 2 0 2 2 2 0 2 0 0 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features[:5])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3, activation=\"softmax\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.18006371, 0.6033592 , 0.21657713],\n",
       "       [0.17465869, 0.62154186, 0.20379946],\n",
       "       [0.1298278 , 0.586272  , 0.28390017],\n",
       "       [0.11674696, 0.60692537, 0.2763277 ],\n",
       "       [0.12682088, 0.59196156, 0.28121752]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Compile the keras model\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=loss_object,\n",
    "             metrics=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.9657 - mse: 1.1823 - accuracy: 0.5909\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 921us/step - loss: 0.8147 - mse: 1.2449 - accuracy: 0.7031\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 855us/step - loss: 0.7582 - mse: 1.2568 - accuracy: 0.8596\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 899us/step - loss: 0.7005 - mse: 1.2753 - accuracy: 0.9646\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 891us/step - loss: 0.6557 - mse: 1.2985 - accuracy: 0.9750\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 875us/step - loss: 0.6285 - mse: 1.3162 - accuracy: 0.9766\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 873us/step - loss: 0.6125 - mse: 1.3277 - accuracy: 0.9758\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 887us/step - loss: 0.6026 - mse: 1.3352 - accuracy: 0.9760\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 877us/step - loss: 0.5961 - mse: 1.3403 - accuracy: 0.9760\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 867us/step - loss: 0.5915 - mse: 1.3440 - accuracy: 0.9760\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 891us/step - loss: 0.5881 - mse: 1.3467 - accuracy: 0.9758\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 853us/step - loss: 0.5855 - mse: 1.3488 - accuracy: 0.9755\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 833us/step - loss: 0.5835 - mse: 1.3504 - accuracy: 0.9758\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 839us/step - loss: 0.5818 - mse: 1.3518 - accuracy: 0.9750\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 847us/step - loss: 0.5804 - mse: 1.3529 - accuracy: 0.9753\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 842us/step - loss: 0.5792 - mse: 1.3538 - accuracy: 0.9753\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 827us/step - loss: 0.5782 - mse: 1.3545 - accuracy: 0.9758\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 856us/step - loss: 0.5772 - mse: 1.3552 - accuracy: 0.9753\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 944us/step - loss: 0.5764 - mse: 1.3558 - accuracy: 0.9768\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 925us/step - loss: 0.5757 - mse: 1.3563 - accuracy: 0.9779\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 905us/step - loss: 0.5750 - mse: 1.3567 - accuracy: 0.9805\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 803us/step - loss: 0.5744 - mse: 1.3571 - accuracy: 0.9828\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 795us/step - loss: 0.5738 - mse: 1.3575 - accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 792us/step - loss: 0.5733 - mse: 1.3578 - accuracy: 0.9852\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 825us/step - loss: 0.5728 - mse: 1.3581 - accuracy: 0.9859\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 849us/step - loss: 0.5723 - mse: 1.3584 - accuracy: 0.9862\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 832us/step - loss: 0.5719 - mse: 1.3587 - accuracy: 0.9857\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 867us/step - loss: 0.5715 - mse: 1.3589 - accuracy: 0.9867\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 868us/step - loss: 0.5711 - mse: 1.3592 - accuracy: 0.9859\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 875us/step - loss: 0.5707 - mse: 1.3594 - accuracy: 0.9872\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 825us/step - loss: 0.5703 - mse: 1.3596 - accuracy: 0.9878\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 828us/step - loss: 0.5701 - mse: 1.3598 - accuracy: 0.9867\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 850us/step - loss: 0.5696 - mse: 1.3600 - accuracy: 0.9885\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 853us/step - loss: 0.5694 - mse: 1.3602 - accuracy: 0.9878\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 910us/step - loss: 0.5691 - mse: 1.3603 - accuracy: 0.9880\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 891us/step - loss: 0.5689 - mse: 1.3605 - accuracy: 0.9883\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 876us/step - loss: 0.5685 - mse: 1.3607 - accuracy: 0.9888\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 890us/step - loss: 0.5683 - mse: 1.3608 - accuracy: 0.9909\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 835us/step - loss: 0.5681 - mse: 1.3610 - accuracy: 0.9898\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 862us/step - loss: 0.5678 - mse: 1.3611 - accuracy: 0.9901\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 822us/step - loss: 0.5675 - mse: 1.3613 - accuracy: 0.9914\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 839us/step - loss: 0.5673 - mse: 1.3614 - accuracy: 0.9917\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 879us/step - loss: 0.5671 - mse: 1.3615 - accuracy: 0.9909\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.5670 - mse: 1.3616 - accuracy: 0.9906\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 968us/step - loss: 0.5668 - mse: 1.3618 - accuracy: 0.9909\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 844us/step - loss: 0.5666 - mse: 1.3619 - accuracy: 0.9906\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 820us/step - loss: 0.5663 - mse: 1.3620 - accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 849us/step - loss: 0.5661 - mse: 1.3621 - accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 880us/step - loss: 0.5659 - mse: 1.3622 - accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 856us/step - loss: 0.5658 - mse: 1.3623 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=120,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((32, 4), (32,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 93.313%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in test_dataset.take(50):\n",
    "    # training=False is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    logits = model(x, training=False)\n",
    "    prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    test_accuracy(prediction, y)\n",
    "\n",
    "    \n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 2), dtype=int32, numpy=\n",
       "array([[0, 0],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([y,prediction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = create_dataset(train_dataset_fp, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_dataset(test_dataset_fp, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input layer of feature columns\n",
    "feature_columns = {header: tf.feature_column.numeric_column(header) for header in FEATURE_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.DenseFeatures(feature_columns=feature_columns.values()),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3, activation=\"softmax\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Compile the keras model\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=loss_object,\n",
    "             metrics=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 948us/step - loss: 0.9168 - mse: 1.2799 - accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 893us/step - loss: 0.8460 - mse: 1.3235 - accuracy: 0.7000\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 888us/step - loss: 0.8385 - mse: 1.3233 - accuracy: 0.7000\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 879us/step - loss: 0.7006 - mse: 1.2886 - accuracy: 0.9193\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 883us/step - loss: 0.6204 - mse: 1.3226 - accuracy: 0.9773\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 874us/step - loss: 0.5997 - mse: 1.3374 - accuracy: 0.9823\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 859us/step - loss: 0.5903 - mse: 1.3444 - accuracy: 0.9833\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 858us/step - loss: 0.5848 - mse: 1.3485 - accuracy: 0.9833\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 865us/step - loss: 0.5810 - mse: 1.3513 - accuracy: 0.9833\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 836us/step - loss: 0.5783 - mse: 1.3533 - accuracy: 0.9833\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 835us/step - loss: 0.5763 - mse: 1.3548 - accuracy: 0.9833\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 864us/step - loss: 0.5747 - mse: 1.3559 - accuracy: 0.9836\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 832us/step - loss: 0.5734 - mse: 1.3569 - accuracy: 0.9846\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 808us/step - loss: 0.5722 - mse: 1.3577 - accuracy: 0.9857\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 829us/step - loss: 0.5714 - mse: 1.3583 - accuracy: 0.9862\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 829us/step - loss: 0.5706 - mse: 1.3588 - accuracy: 0.9880\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 869us/step - loss: 0.5699 - mse: 1.3593 - accuracy: 0.9891\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 854us/step - loss: 0.5692 - mse: 1.3597 - accuracy: 0.9911\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 850us/step - loss: 0.5686 - mse: 1.3601 - accuracy: 0.9914\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 857us/step - loss: 0.5683 - mse: 1.3604 - accuracy: 0.9906\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 835us/step - loss: 0.5677 - mse: 1.3607 - accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 872us/step - loss: 0.5674 - mse: 1.3610 - accuracy: 0.9917\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 871us/step - loss: 0.5668 - mse: 1.3613 - accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 852us/step - loss: 0.5665 - mse: 1.3615 - accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 845us/step - loss: 0.5662 - mse: 1.3617 - accuracy: 0.9917\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 856us/step - loss: 0.5657 - mse: 1.3620 - accuracy: 0.9917\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 862us/step - loss: 0.5654 - mse: 1.3622 - accuracy: 0.9917\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 871us/step - loss: 0.5652 - mse: 1.3624 - accuracy: 0.9917\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 877us/step - loss: 0.5648 - mse: 1.3626 - accuracy: 0.9917\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 834us/step - loss: 0.5647 - mse: 1.3627 - accuracy: 0.9917\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 908us/step - loss: 0.5645 - mse: 1.3629 - accuracy: 0.9917\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 923us/step - loss: 0.5641 - mse: 1.3631 - accuracy: 0.9917\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 955us/step - loss: 0.5640 - mse: 1.3632 - accuracy: 0.9917\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 859us/step - loss: 0.5637 - mse: 1.3634 - accuracy: 0.9917\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 824us/step - loss: 0.5634 - mse: 1.3636 - accuracy: 0.9917\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 826us/step - loss: 0.5633 - mse: 1.3637 - accuracy: 0.9917\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 828us/step - loss: 0.5632 - mse: 1.3638 - accuracy: 0.9917\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 831us/step - loss: 0.5629 - mse: 1.3640 - accuracy: 0.9917\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 817us/step - loss: 0.5626 - mse: 1.3642 - accuracy: 0.9917\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 819us/step - loss: 0.5624 - mse: 1.3643 - accuracy: 0.9917\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 825us/step - loss: 0.5622 - mse: 1.3644 - accuracy: 0.9917\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 816us/step - loss: 0.5622 - mse: 1.3645 - accuracy: 0.9917\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 826us/step - loss: 0.5620 - mse: 1.3647 - accuracy: 0.9917\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 824us/step - loss: 0.5620 - mse: 1.3647 - accuracy: 0.9917\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 797us/step - loss: 0.5617 - mse: 1.3649 - accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 858us/step - loss: 0.5616 - mse: 1.3650 - accuracy: 0.9917\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 936us/step - loss: 0.5614 - mse: 1.3651 - accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 838us/step - loss: 0.5613 - mse: 1.3652 - accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 825us/step - loss: 0.5613 - mse: 1.3653 - accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 864us/step - loss: 0.5611 - mse: 1.3653 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=120,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.875%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in test_dataset:\n",
    "    # training=False is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    logits = model(x, training=False)\n",
    "    prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    test_accuracy(prediction, y)\n",
    "    break\n",
    "    \n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 2), dtype=int32, numpy=\n",
       "array([[2, 2],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [2, 2],\n",
       "       [0, 0],\n",
       "       [1, 2],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [0, 0],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1]])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([y,prediction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
