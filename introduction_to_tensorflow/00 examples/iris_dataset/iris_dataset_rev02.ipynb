{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: C:\\Users\\LONAA32\\.keras\\datasets\\iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "test_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "test_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(test_dataset_url),\n",
    "                                          origin=test_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(file_path, batch_size=1):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(file_path,\n",
    "                                                    batch_size,\n",
    "                                                    column_names=COLUMN_NAMES,\n",
    "                                                    label_name=LABEL_NAME)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "# column order in CSV file\n",
    "COLUMN_NAMES = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "FEATURE_NAMES = COLUMN_NAMES[:-1]\n",
    "LABEL_NAME = COLUMN_NAMES[-1]\n",
    "\n",
    "print(\"Features: {}\".format(FEATURE_NAMES))\n",
    "print(\"Label: {}\".format(LABEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = create_dataset(train_dataset_fp, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_dataset(test_dataset_fp, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('sepal_length', array([7.2], dtype=float32)), ('sepal_width', array([3.], dtype=float32)), ('petal_length', array([5.8], dtype=float32)), ('petal_width', array([1.6], dtype=float32))]), array([2]))\n"
     ]
    }
   ],
   "source": [
    "for element in train_dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "    \"\"\"Pack the features into a single array.\"\"\"\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5.2 2.7 3.9 1.4]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.7 3.  5.  1.7]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.5 2.4 3.7 1. ]], shape=(32, 4), dtype=float32)\n",
      "tf.Tensor([1 2 1 1 2 1 0 1 0 0 2 2 1 2 1 0 2 1 1 1 0 2 2 1 0 0 2 0 2 1 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input layer of feature columns\n",
    "feature_columns = {header: tf.feature_column.numeric_column(header) for header in FEATURE_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "# TODO 2a\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3, activation=\"softmax\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "# TODO 2a\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.DenseFeatures(feature_columns=feature_columns.values()),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3, activation=\"softmax\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.422602  , 0.06274351, 0.5146545 ],\n",
       "       [0.3391083 , 0.02939623, 0.6314955 ],\n",
       "       [0.40758455, 0.04595266, 0.5464628 ],\n",
       "       [0.40852743, 0.05661747, 0.53485507],\n",
       "       [0.38273373, 0.04433028, 0.572936  ]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the keras model\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=loss_object,\n",
    "             metrics=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 950us/step - loss: 0.9969 - mse: 1.1738 - accuracy: 0.5516\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 867us/step - loss: 0.8056 - mse: 1.2593 - accuracy: 0.7005\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 831us/step - loss: 0.7536 - mse: 1.2712 - accuracy: 0.7883\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 875us/step - loss: 0.6893 - mse: 1.2858 - accuracy: 0.9526\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 863us/step - loss: 0.6344 - mse: 1.3129 - accuracy: 0.9758\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 883us/step - loss: 0.6099 - mse: 1.3295 - accuracy: 0.9766\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 933us/step - loss: 0.5982 - mse: 1.3383 - accuracy: 0.9784\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 899us/step - loss: 0.5918 - mse: 1.3435 - accuracy: 0.9786\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 858us/step - loss: 0.5875 - mse: 1.3469 - accuracy: 0.9786\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 867us/step - loss: 0.5845 - mse: 1.3493 - accuracy: 0.9797\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 858us/step - loss: 0.5823 - mse: 1.3510 - accuracy: 0.9789\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 829us/step - loss: 0.5806 - mse: 1.3524 - accuracy: 0.9797\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 850us/step - loss: 0.5793 - mse: 1.3535 - accuracy: 0.9802\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 850us/step - loss: 0.5782 - mse: 1.3543 - accuracy: 0.9792\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 858us/step - loss: 0.5771 - mse: 1.3550 - accuracy: 0.9797\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 872us/step - loss: 0.5763 - mse: 1.3556 - accuracy: 0.9807\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 827us/step - loss: 0.5755 - mse: 1.3562 - accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 841us/step - loss: 0.5749 - mse: 1.3566 - accuracy: 0.9833\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 849us/step - loss: 0.5743 - mse: 1.3570 - accuracy: 0.9857\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 908us/step - loss: 0.5737 - mse: 1.3573 - accuracy: 0.9872\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 914us/step - loss: 0.5732 - mse: 1.3577 - accuracy: 0.9880\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 850us/step - loss: 0.5727 - mse: 1.3580 - accuracy: 0.9880\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 821us/step - loss: 0.5723 - mse: 1.3582 - accuracy: 0.9878\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 876us/step - loss: 0.5719 - mse: 1.3585 - accuracy: 0.9885\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 825us/step - loss: 0.5715 - mse: 1.3587 - accuracy: 0.9883\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 867us/step - loss: 0.5712 - mse: 1.3590 - accuracy: 0.9878\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 872us/step - loss: 0.5709 - mse: 1.3592 - accuracy: 0.9872\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 907us/step - loss: 0.5705 - mse: 1.3594 - accuracy: 0.9875\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 874us/step - loss: 0.5702 - mse: 1.3596 - accuracy: 0.9891\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 842us/step - loss: 0.5699 - mse: 1.3598 - accuracy: 0.9883\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 868us/step - loss: 0.5696 - mse: 1.3600 - accuracy: 0.9885\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 883us/step - loss: 0.5694 - mse: 1.3601 - accuracy: 0.9893\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 871us/step - loss: 0.5691 - mse: 1.3603 - accuracy: 0.9888\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 938us/step - loss: 0.5689 - mse: 1.3604 - accuracy: 0.9893\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 906us/step - loss: 0.5688 - mse: 1.3606 - accuracy: 0.9891\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 833us/step - loss: 0.5685 - mse: 1.3607 - accuracy: 0.9896\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 851us/step - loss: 0.5682 - mse: 1.3608 - accuracy: 0.9904\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 879us/step - loss: 0.5681 - mse: 1.3609 - accuracy: 0.9909\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.5679 - mse: 1.3611 - accuracy: 0.9901\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 917us/step - loss: 0.5678 - mse: 1.3612 - accuracy: 0.9896\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 869us/step - loss: 0.5675 - mse: 1.3613 - accuracy: 0.9909\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 855us/step - loss: 0.5674 - mse: 1.3613 - accuracy: 0.9909\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 923us/step - loss: 0.5671 - mse: 1.3615 - accuracy: 0.9911\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 885us/step - loss: 0.5671 - mse: 1.3616 - accuracy: 0.9909\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 889us/step - loss: 0.5668 - mse: 1.3617 - accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 859us/step - loss: 0.5667 - mse: 1.3618 - accuracy: 0.9917\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 908us/step - loss: 0.5666 - mse: 1.3618 - accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 905us/step - loss: 0.5664 - mse: 1.3619 - accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 863us/step - loss: 0.5663 - mse: 1.3620 - accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 824us/step - loss: 0.5661 - mse: 1.3621 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=120,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((32, 4), (32,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 93.313%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in test_dataset.take(50):\n",
    "    # training=False is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    logits = model(x, training=False)\n",
    "    prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    test_accuracy(prediction, y)\n",
    "\n",
    "    \n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [2, 2],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [2, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([y,prediction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
