{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "cwd = os.getcwd()\n",
    "train_file_path = os.path.join(cwd, \"train.csv\")\n",
    "test_file_path = os.path.join(cwd, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
      "\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q\n",
      "\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(test_file_path) as f:\n",
    "    for _ in range(3): # first 10 lines\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify label column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMN = 'Survived'\n",
    "LABELS = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV data from the file and create a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path, **kwargs):\n",
    "    \"Loads a CSV file into a dataset\"\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=file_path,\n",
    "        batch_size=5,\n",
    "        label_name=LABEL_COLUMN,\n",
    "        na_value=\"?\",\n",
    "        num_epochs=1,\n",
    "        **kwargs\n",
    "        )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = get_dataset(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset):\n",
    "    # take one batch of 5 and print it\n",
    "    for batch, label in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key,value.numpy()))\n",
    "        print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (5 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         : [143 544 853 741 349]\n",
      "Pclass              : [3 2 3 1 3]\n",
      "Name                : [b'Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)'\n",
      " b'Beane, Mr. Edward' b'Boulos, Miss. Nourelain'\n",
      " b'Hawksford, Mr. Walter James' b'Coutts, Master. William Loch \"William\"']\n",
      "Sex                 : [b'female' b'male' b'female' b'male' b'male']\n",
      "Age                 : [24. 32.  9.  0.  3.]\n",
      "SibSp               : [1 1 1 0 1]\n",
      "Parch               : [0 0 1 0 1]\n",
      "Ticket              : [b'STON/O2. 3101279' b'2908' b'2678' b'16988' b'C.A. 37671']\n",
      "Fare                : [15.85   26.     15.2458 30.     15.9   ]\n",
      "Cabin               : [b'' b'' b'' b'D45' b'']\n",
      "Embarked            : [b'S' b'S' b'C' b'S' b'S']\n",
      "Label: tf.Tensor([1 1 0 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "show_batch(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the CSV are named. The dataset constructor will pick these names up automatically. If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass              : [3 1 3 3 1]\n",
      "Sex                 : [b'male' b'male' b'female' b'female' b'male']\n",
      "Age                 : [ 1. 26. 29.  2. 40.]\n",
      "SibSp               : [5 0 1 3 0]\n",
      "Cabin               : [b'' b'C148' b'G6' b'' b'']\n",
      "Label: tf.Tensor([0 1 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "SELECT_COLUMNS = ['Survived', 'Age', 'SibSp', 'Pclass', 'Cabin', 'Sex']\n",
    "\n",
    "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
