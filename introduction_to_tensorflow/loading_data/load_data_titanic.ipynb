{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "cwd = os.getcwd()\n",
    "train_file_path = os.path.join(cwd, \"train.csv\")\n",
    "test_file_path = os.path.join(cwd, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
      "\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q\n",
      "\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(test_file_path) as f:\n",
    "    for _ in range(3): # first 10 lines\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify label column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMN = 'Survived'\n",
    "LABELS = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV data from the file and create a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path, **kwargs):\n",
    "    \"Loads a CSV file into a dataset\"\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=file_path,\n",
    "        batch_size=5,\n",
    "        label_name=LABEL_COLUMN,\n",
    "        na_value=\"?\",\n",
    "        num_epochs=1,\n",
    "        **kwargs\n",
    "        )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = get_dataset(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset):\n",
    "    # take one batch of 5 and print it\n",
    "    for batch, label in dataset.take(1):\n",
    "        for key, value in batch.items():\n",
    "            print(\"{:20s}: {}\".format(key,value.numpy()))\n",
    "        print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (5 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         : [143 544 853 741 349]\n",
      "Pclass              : [3 2 3 1 3]\n",
      "Name                : [b'Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)'\n",
      " b'Beane, Mr. Edward' b'Boulos, Miss. Nourelain'\n",
      " b'Hawksford, Mr. Walter James' b'Coutts, Master. William Loch \"William\"']\n",
      "Sex                 : [b'female' b'male' b'female' b'male' b'male']\n",
      "Age                 : [24. 32.  9.  0.  3.]\n",
      "SibSp               : [1 1 1 0 1]\n",
      "Parch               : [0 0 1 0 1]\n",
      "Ticket              : [b'STON/O2. 3101279' b'2908' b'2678' b'16988' b'C.A. 37671']\n",
      "Fare                : [15.85   26.     15.2458 30.     15.9   ]\n",
      "Cabin               : [b'' b'' b'' b'D45' b'']\n",
      "Embarked            : [b'S' b'S' b'C' b'S' b'S']\n",
      "Label: tf.Tensor([1 1 0 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "show_batch(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the CSV are named. The dataset constructor will pick these names up automatically. If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass              : [3 1 3 3 1]\n",
      "Sex                 : [b'male' b'male' b'female' b'female' b'male']\n",
      "Age                 : [ 1. 26. 29.  2. 40.]\n",
      "SibSp               : [5 0 1 3 0]\n",
      "Cabin               : [b'' b'C148' b'G6' b'' b'']\n",
      "Label: tf.Tensor([0 1 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "SELECT_COLUMNS = ['Survived', 'Age', 'SibSp', 'Pclass', 'Cabin', 'Sex']\n",
    "\n",
    "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "A CSV file can contain a variety of data types. Typically you want to convert from those mixed types to a fixed length vector before feeding the data into your model.\n",
    "\n",
    "TensorFlow has a built-in system for describing common input conversions: `tf.feature_column`, see [this tutorial](../keras/feature_columns) for details.\n",
    "\n",
    "\n",
    "You can preprocess your data using any tool you like (like [nltk](https://www.nltk.org/) or [sklearn](https://scikit-learn.org/stable/)), and just pass the processed output to TensorFlow. \n",
    "\n",
    "\n",
    "The primary advantage of doing the preprocessing inside your model is that when you export the model it includes the preprocessing. This way you can pass the raw data directly to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data is already in an appropriate numeric format, you can pack the data into a vector before passing it off to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass              : [3. 3. 2. 3. 3.]\n",
      "Age                 : [29. 11. 19.  0. 44.]\n",
      "SibSp               : [1. 0. 0. 0. 0.]\n",
      "Fare                : [10.4625 18.7875 10.5     7.2292  8.05  ]\n",
      "Label: tf.Tensor([0 0 1 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "SELECT_COLUMNS = ['Survived', 'Age', 'SibSp', 'Pclass', 'Fare']\n",
    "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
    "temp_dataset = get_dataset(train_file_path, \n",
    "                           select_columns=SELECT_COLUMNS,\n",
    "                           column_defaults = DEFAULTS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch, labels_batch = next(iter(temp_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Pclass',\n",
       "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 3., 1., 1., 1.], dtype=float32)>),\n",
       "             ('Age',\n",
       "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([40., 17., 54., 38., 34.], dtype=float32)>),\n",
       "             ('SibSp',\n",
       "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>),\n",
       "             ('Fare',\n",
       "              <tf.Tensor: shape=(5,), dtype=float32, numpy=array([153.4625,   8.6625,  51.8625, 227.525 ,  26.55  ], dtype=float32)>)])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple function that will pack together all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(features, label):\n",
    "    return tf.stack(list(example_batch.values()), axis=-1), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map pack function to dataset\n",
    "packed_dataset = temp_dataset.map(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.      40.       0.     153.4625]\n",
      " [  3.      17.       0.       8.6625]\n",
      " [  1.      54.       0.      51.8625]\n",
      " [  1.      38.       0.     227.525 ]\n",
      " [  1.      34.       0.      26.55  ]]\n",
      "\n",
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for features, labels in packed_dataset.take(1):\n",
    "  print(features.numpy())\n",
    "  print()\n",
    "  print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have mixed datatypes you may want to separate out these simple-numeric fields. The `tf.feature_column` api can handle them, but this incurs some overhead and should be avoided unless really necessary. Switch back to the mixed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         : [137 521 289 517 727]\n",
      "Pclass              : [1 1 2 2 2]\n",
      "Name                : [b'Newsom, Miss. Helen Monypeny' b'Perreault, Miss. Anne'\n",
      " b'Hosono, Mr. Masabumi' b'Lemore, Mrs. (Amelia Milley)'\n",
      " b'Renouf, Mrs. Peter Henry (Lillian Jefferys)']\n",
      "Sex                 : [b'female' b'female' b'male' b'female' b'female']\n",
      "Age                 : [19. 30. 42. 34. 30.]\n",
      "SibSp               : [0 0 0 0 3]\n",
      "Parch               : [2 0 0 0 0]\n",
      "Ticket              : [b'11752' b'12749' b'237798' b'C.A. 34260' b'31027']\n",
      "Fare                : [26.2833 93.5    13.     10.5    21.    ]\n",
      "Cabin               : [b'D47' b'B73' b'' b'F33' b'']\n",
      "Embarked            : [b'S' b'S' b'S' b'S' b'S']\n",
      "Label: tf.Tensor([1 1 1 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "show_batch(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So define a more general preprocessor that selects a list of numeric features and packs them into a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackNumericFeatures():\n",
    "    \n",
    "    def __init__(self, column_names):\n",
    "        self.names = column_names\n",
    "        \n",
    "    def __call__(self, features, labels):\n",
    "        numeric_features = [features.pop(name) for name in self.names]\n",
    "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
    "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
    "        features['numeric'] = numeric_features\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = ['Pclass','Age','SibSp', 'Parch', 'Fare']\n",
    "\n",
    "packed_train_data = raw_train_data.map(PackNumericFeatures(NUMERIC_FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         : [712 676 209 343  44]\n",
      "Name                : [b'Klaber, Mr. Herman' b'Edvardsson, Mr. Gustaf Hjalmar'\n",
      " b'Carr, Miss. Helen \"Ellen\"' b'Collander, Mr. Erik Gustaf'\n",
      " b'Laroche, Miss. Simonne Marie Anne Andree']\n",
      "Sex                 : [b'male' b'male' b'female' b'male' b'female']\n",
      "Ticket              : [b'113028' b'349912' b'367231' b'248740' b'SC/Paris 2123']\n",
      "Cabin               : [b'C124' b'' b'' b'' b'']\n",
      "Embarked            : [b'S' b'S' b'Q' b'S' b'C']\n",
      "numeric             : [[ 1.      0.      0.      0.     26.55  ]\n",
      " [ 3.     18.      0.      0.      7.775 ]\n",
      " [ 3.     16.      0.      0.      7.75  ]\n",
      " [ 2.     28.      0.      0.     13.    ]\n",
      " [ 2.      3.      1.      2.     41.5792]]\n",
      "Label: tf.Tensor([0 0 1 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "show_batch(packed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch, labels_batch = next(iter(packed_train_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalization\n",
    "\n",
    "Continuous data should always be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = np.array(desc.T['mean'])\n",
    "STD = np.array(desc.T['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.30864198 29.69911765  0.52300786  0.38159371 32.20420797] [ 0.83607124 14.52649733  1.10274343  0.80605722 49.6934286 ]\n"
     ]
    }
   ],
   "source": [
    "print(MEAN, STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numeric_data(data, mean, std):\n",
    "  # Center the data\n",
    "  return (data-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a numeric column. The `tf.feature_columns.numeric_column` API accepts a `normalizer_fn` argument, which will be run on each batch.\n",
    "\n",
    "Bind the `MEAN` and `STD` to the normalizer fn using [`functools.partial`](https://docs.python.org/3/library/functools.html#functools.partial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to use partial here to pass the two variables to the function\n",
    "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
    "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
    "numeric_columns = [numeric_column]\n",
    "numeric_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you train the model, include this feature column to select and center this block of numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[  1.    ,   0.    ,   0.    ,   0.    , 221.7792],\n",
       "       [  3.    ,   0.    ,   0.    ,   0.    ,   7.3125],\n",
       "       [  3.    ,  26.    ,   1.    ,   0.    ,   7.8542],\n",
       "       [  3.    ,   0.    ,   1.    ,   0.    ,  16.1   ],\n",
       "       [  3.    ,  36.    ,   1.    ,   1.    ,  24.15  ]], dtype=float32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5652277 , -2.044479  , -0.47427887, -0.47340772,  3.8148906 ],\n",
       "       [ 0.8269129 , -2.044479  , -0.47427887, -0.47340772, -0.50090545],\n",
       "       [ 0.8269129 , -0.25464624,  0.43255043, -0.47340772, -0.4900046 ],\n",
       "       [ 0.8269129 , -2.044479  ,  0.43255043, -0.47340772, -0.32407117],\n",
       "       [ 0.8269129 ,  0.433751  ,  0.43255043,  0.767199  , -0.16207795]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
    "numeric_layer(example_batch).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "\n",
    "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
    "\n",
    "Use the `tf.feature_column` API to create a collection with a `tf.feature_column.indicator_column` for each categorical column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'Sex': ['male', 'female'],\n",
    "    'Embarked' : ['C', 'S', 'Q'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "for feature, vocab in CATEGORIES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(key=feature, vocabulary_list=vocab)\n",
    "    categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Embarked', vocabulary_list=('C', 'S', 'Q'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
    "categorical_layer(example_batch).numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined preprocessing layer\n",
    "\n",
    "Add the two feature column collections and pass them to a `tf.keras.layers.DenseFeatures` to create an input layer that will extract and preprocess both input types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.          0.          0.          1.          0.8269129\n",
      " -0.66768456 -0.47427887 -0.47340772 -0.47373885]\n"
     ]
    }
   ],
   "source": [
    "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)\n",
    "print(preprocessing_layer(example_batch).numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "\n",
    "A next step would be to build a build a `tf.keras.Sequential`, starting with the `preprocessing_layer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
